{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pandas/compat/_optional.py:161: UserWarning: Pandas requires version '2.7.1' or newer of 'numexpr' (version '2.7.0' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../data/preprocessed/3_month_retail.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "with open('../data/preprocessed/cluster_store.json','r') as f:\n",
    "    cluster = json.load(f)\n",
    "with open('../data/preprocessed/cluster_key_store_num.json', 'r') as f:\n",
    "    cluster_key_store = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster 번호를 지정해주면, 거기 안의 데이터를 X로 return 해주는 함수를 만들자\n",
    "def cluster_dataset(cluster_num):\n",
    "    data_tensor = torch.tensor([])\n",
    "    for store_id in cluster[cluster_num]:\n",
    "        sub_tensor = torch.tensor(list(data[str(store_id)].values()))\n",
    "        data_tensor = torch.cat((data_tensor,sub_tensor),0)\n",
    "    return data_tensor[:,:-1].t(), data_tensor[:,-1].t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define store_nums\n",
    "store_list = [*range(1,643)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DSModel0(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DSModel0, self).__init__()\n",
    "        \n",
    "        self.ln = nn.LayerNorm(7848)\n",
    "        self.conv_1 = nn.Conv2d(1, 1, kernel_size=(4,4))\n",
    "\n",
    "        self.fc1 = nn.Linear(324, 64)\n",
    "        self.fc2 = nn.Linear(64, 8)\n",
    "        self.fc3 = nn.Linear(8,1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(1, 1, 7848)\n",
    "        x = self.ln(x)\n",
    "        x = x.reshape(1, 1, 18, 436)\n",
    "        x = F.relu(self.conv_1(x))\n",
    "        x = F.max_pool2d(x, (4, 4))\n",
    "        x = x.reshape(1,324)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "class DSModel1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DSModel1, self).__init__()\n",
    "        \n",
    "        self.ln = nn.LayerNorm(1098)\n",
    "        self.conv_1 = nn.Conv2d(1, 1, kernel_size=(4,4))\n",
    "\n",
    "        self.fc1 = nn.Linear(42, 8)\n",
    "        self.fc2 = nn.Linear(8,1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(1, 1, 1098)\n",
    "        x = self.ln(x)\n",
    "        x = x.reshape(1, 1, 18, 61)\n",
    "        x = F.relu(self.conv_1(x))\n",
    "        x = F.max_pool2d(x, (4, 4))\n",
    "        x = x.reshape(1, 42)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "class DSModel2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DSModel2, self).__init__()\n",
    "        \n",
    "        self.ln = nn.LayerNorm(2610)\n",
    "        self.conv_1 = nn.Conv2d(1, 1, kernel_size=(4,4))\n",
    "\n",
    "        self.fc1 = nn.Linear(105, 32)\n",
    "        self.fc2 = nn.Linear(32,8)\n",
    "        self.fc3 = nn.Linear(8,1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(1,1, 2610)\n",
    "        x = self.ln(x)\n",
    "        x = x.reshape(1, 1, 18, 145)\n",
    "        x = F.relu(self.conv_1(x))\n",
    "        x = F.max_pool2d(x, (4, 4))\n",
    "        x = x.reshape(1,32)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/work/.dsproject/notebooks/Modeling3.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://dlspace.kt.co.kr:10627/home/work/.dsproject/notebooks/Modeling3.ipynb#ch0000007vscode-remote?line=40'>41</a>\u001b[0m         outputs \u001b[39m=\u001b[39m model(inputs)\u001b[39m.\u001b[39mflatten()\n\u001b[1;32m     <a href='vscode-notebook-cell://dlspace.kt.co.kr:10627/home/work/.dsproject/notebooks/Modeling3.ipynb#ch0000007vscode-remote?line=41'>42</a>\u001b[0m         loss \u001b[39m=\u001b[39m criterion(outputs, value)\n\u001b[0;32m---> <a href='vscode-notebook-cell://dlspace.kt.co.kr:10627/home/work/.dsproject/notebooks/Modeling3.ipynb#ch0000007vscode-remote?line=42'>43</a>\u001b[0m         loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://dlspace.kt.co.kr:10627/home/work/.dsproject/notebooks/Modeling3.ipynb#ch0000007vscode-remote?line=43'>44</a>\u001b[0m         optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell://dlspace.kt.co.kr:10627/home/work/.dsproject/notebooks/Modeling3.ipynb#ch0000007vscode-remote?line=45'>46</a>\u001b[0m         \u001b[39m# running_loss += loss.item()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://dlspace.kt.co.kr:10627/home/work/.dsproject/notebooks/Modeling3.ipynb#ch0000007vscode-remote?line=46'>47</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://dlspace.kt.co.kr:10627/home/work/.dsproject/notebooks/Modeling3.ipynb#ch0000007vscode-remote?line=47'>48</a>\u001b[0m \u001b[39m#item inference\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py:166\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    162\u001b[0m inputs \u001b[39m=\u001b[39m (inputs,) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(inputs, torch\u001b[39m.\u001b[39mTensor) \u001b[39melse\u001b[39;00m \\\n\u001b[1;32m    163\u001b[0m     \u001b[39mtuple\u001b[39m(inputs) \u001b[39mif\u001b[39;00m inputs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mtuple\u001b[39m()\n\u001b[1;32m    165\u001b[0m grad_tensors_ \u001b[39m=\u001b[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001b[39mlen\u001b[39m(tensors))\n\u001b[0;32m--> 166\u001b[0m grad_tensors_ \u001b[39m=\u001b[39m _make_grads(tensors, grad_tensors_, is_grads_batched\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    167\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py:66\u001b[0m, in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39melif\u001b[39;00m grad \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m out\u001b[39m.\u001b[39mrequires_grad:\n\u001b[0;32m---> 66\u001b[0m         \u001b[39mif\u001b[39;00m out\u001b[39m.\u001b[39;49mnumel() \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m     67\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgrad can be implicitly created only for scalar outputs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     68\u001b[0m         new_grads\u001b[39m.\u001b[39mappend(torch\u001b[39m.\u001b[39mones_like(out, memory_format\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mpreserve_format))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "result_tensor = torch.tensor([]).to(device)\n",
    "\n",
    "for store_id in store_list:\n",
    "    #상점이 어느 cluster에 해당하는지\n",
    "    cluster_num = cluster_key_store[str(store_id)]\n",
    "    # X = cluster_dataset(cluster_num)\n",
    "    # X_train = X[:27]\n",
    "    # X_test = X[27:]\n",
    "    X_train, X_test = cluster_dataset(cluster_num)\n",
    "    # X_train, X_test size : (28, ~)\n",
    "    X_train = X_train.to(device)\n",
    "    X_test = X_test.to(device)\n",
    "    #product\n",
    "    loss_ = {}\n",
    "    for item in data[str(store_id)].keys():\n",
    "        y = torch.tensor(data[str(store_id)][item][1:]).float()\n",
    "        y_train = y \n",
    "        y_train = y_train.to(device)\n",
    "        dataset_train = TensorDataset(X_train, y_train)\n",
    "        train_dataloader = DataLoader(dataset_train, batch_size=1, shuffle=False)\n",
    "\n",
    "        if cluster_num == '0':\n",
    "            model = DSModel0()\n",
    "        elif cluster_num == '1':\n",
    "            model = DSModel1()\n",
    "        elif cluster_num == '2':\n",
    "            model = DSModel2()\n",
    "\n",
    "\n",
    "        model = model.to(device)\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr = 0.001, weight_decay=1e-7)\n",
    "\n",
    "        # item_loss = 0.0\n",
    "        for epoch in range(20):\n",
    "            # running_loss = 0.0\n",
    "            for i, data_input in enumerate(train_dataloader,0):\n",
    "                inputs, value = data_input\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs).flatten()\n",
    "                loss = criterion(outputs, value)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # running_loss += loss.item()\n",
    "\n",
    "        #item inference\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(X_test)\n",
    "        result_tensor = torch.cat((result_tensor, y_pred),0)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_tensor을 dataframe으로 전환\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "result_tensor_df = pd.DataFrame(result_tensor.detach().cpu().numpy())\n",
    "\n",
    "#round시키고 int로 바꿔야함\n",
    "result_tensor_df = result_tensor_df.round(0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bracket': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'Brush': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0],\n",
       " 'Steak': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  1],\n",
       " 'Shrimp': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  0],\n",
       " 'Power Cord': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0],\n",
       " 'Phone Charger': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  3,\n",
       "  7,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  4,\n",
       "  7,\n",
       "  4,\n",
       "  6,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  0],\n",
       " 'Paint': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'Noodles': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  3,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  0],\n",
       " 'Nails': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'Mouse': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  4,\n",
       "  2,\n",
       "  4,\n",
       "  2,\n",
       "  1,\n",
       "  0],\n",
       " 'Milk': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'King Crab': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0],\n",
       " 'Keyboard': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  4,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  4,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  6,\n",
       "  1],\n",
       " 'Glue': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'Eggs': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0],\n",
       " 'Ear Buds': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  4,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  6,\n",
       "  3,\n",
       "  4,\n",
       "  2,\n",
       "  3,\n",
       "  0],\n",
       " 'Cereal': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'Tape': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_tensor_df.to_csv('first_draft2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
